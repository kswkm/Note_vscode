#로지스틱 회귀(Logistic Regression)
개념: 입력 변수와 출력 클래스 확률을 연결하는 선형 모델
특징: 출력이 0~1 확률 → 특정 클래스 분류, 이진 분류(Binary Classification)에 주로 사용
장점: 단순, 해석 용이
단점: 복잡한 패턴 학습 어려움
예시: 스팸 메일 여부, 질병 유무


#결정 트리(Decision Tree)
개념: 조건문(yes/no) 기반으로 데이터 분류
특징: 트리 구조로 시각화 가능, 연속/범주형 데이터 모두 사용 가능
장점: 직관적, 빠른 예측
단점: 과적합(overfitting) 가능
예시: 고객 이탈 예측, 대출 승인


#랜덤 포레스트(Random Forest)
개념: 여러 개 결정 트리를 만들어 투표(Voting)로 최종 클래스 결정
특징: 앙상블 학습 방법, 과적합 방지, 안정적 성능
장점: 높은 정확도, 다양한 데이터 처리 가능
단점: 트리 수 많으면 느림, 해석 어려움
예시: 질병 진단, 금융 사기 탐지


#서포트 벡터 머신(SVM, Support Vector Machine)
개념: 클래스 간 경계(Hyperplane)를 최대 마진으로 나누는 모델
특징: 선형, 비선형(커널 함수) 모두 가능
장점: 고차원 데이터 분류 우수
단점: 대규모 데이터에서 느림, 매개변수 조정 필요
예시: 이미지 분류, 텍스트 분류


#k-최근접 이웃(K-NN, k-Nearest Neighbors)
개념: 새로운 데이터가 주변 k개의 데이터 중 가장 많은 클래스에 속한다고 분류
특징: 학습 과정 거의 없음(모든 데이터 저장), 예측 시 거리 계산
장점: 단순, 직관적
단점: 데이터 많으면 느림, 스케일 민감
예시: 사용자 행동 예측, 추천 시스템


#나이브 베이즈(Naive Bayes)
개념: 베이즈 정리 기반, 특징 간 독립 가정
특징: 텍스트 데이터 분류에 강점, 계산 빠름
장점: 효율적, 소규모 데이터에서도 작동
단점: 독립 가정이 실제와 다르면 성능 저하
예시: 스팸 메일 분류, 뉴스 카테고리 분류


#인공 신경망(ANN, Neural Network)
개념: 입력층 → 은닉층 → 출력층 구조로 비선형 관계 학습
특징: 복잡한 패턴 학습 가능, 이미지, 음성, 텍스트 등 비정형 데이터에 강점
장점: 높은 정확도, 다양한 데이터 처리 가능
단점: 학습 느림, 해석 어려움
예시: 이미지 객체 인식, 감정 분석

